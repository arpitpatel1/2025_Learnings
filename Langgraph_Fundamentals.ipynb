{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0566104e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard library\n",
    "import os\n",
    "from typing import Type, TypedDict, Annotated, Optional, Literal\n",
    "\n",
    "# Third-party libraries\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api._errors import TranscriptsDisabled, NoTranscriptFound\n",
    "\n",
    "# LangChain OpenAI & HuggingFace\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_huggingface import (\n",
    "    ChatHuggingFace,\n",
    "    HuggingFaceEndpoint,\n",
    "    HuggingFacePipeline,\n",
    ")\n",
    "\n",
    "# LangChain core modules\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import (\n",
    "    StrOutputParser,\n",
    "    JsonOutputParser,\n",
    "    PydanticOutputParser,\n",
    ")\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.tools import tool, InjectedToolArg\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# LangChain prompts & parsing\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "# LangChain community modules\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# LangChain text processing\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# LangChain tools & agents\n",
    "from langchain.tools import BaseTool, StructuredTool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "# openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2b963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb18b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27400b03",
   "metadata": {},
   "source": [
    "### + Conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c2092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentSchema(BaseModel):\n",
    "\n",
    "    sentiment: Literal[\"positive\", \"negative\"] = Field(description='Sentiment of the review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c45c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosisSchema(BaseModel):\n",
    "    issue_type: Literal[\"UX\", \"Performance\", \"Bug\", \"Support\", \"Other\"] = Field(description='The category of issue mentioned in the review')\n",
    "    tone: Literal[\"angry\", \"frustrated\", \"disappointed\", \"calm\"] = Field(description='The emotional tone expressed by the user')\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\"] = Field(description='How urgent or critical the issue appears to be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea4a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model = model.with_structured_output(SentimentSchema)\n",
    "structured_model2 = model.with_structured_output(DiagnosisSchema)\n",
    "prompt = 'What is the sentiment of the following review - The software too good'\n",
    "structured_model.invoke(prompt).sentimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2dd8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewState(TypedDict):\n",
    "\n",
    "    review: str\n",
    "    sentiment: Literal[\"positive\", \"negative\"]\n",
    "    diagnosis: dict\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5bf96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state: ReviewState):\n",
    "\n",
    "    prompt = f'For the following review find out the sentiment \\n {state[\"review\"]}'\n",
    "    sentiment = structured_model.invoke(prompt).sentiment\n",
    "\n",
    "    return {'sentiment': sentiment}\n",
    "\n",
    "def check_sentiment(state: ReviewState) -> Literal[\"positive_response\", \"run_diagnosis\"]:\n",
    "\n",
    "    if state['sentiment'] == 'positive':\n",
    "        return 'positive_response'\n",
    "    else:\n",
    "        return 'run_diagnosis'\n",
    "    \n",
    "def positive_response(state: ReviewState):\n",
    "\n",
    "    prompt = f\"\"\"Write a warm thank-you message in response to this review:\n",
    "    \\n\\n\\\"{state['review']}\\\"\\n\n",
    "Also, kindly ask the user to leave feedback on our website.\"\"\"\n",
    "    \n",
    "    response = model.invoke(prompt).content\n",
    "\n",
    "    return {'response': response}\n",
    "\n",
    "def run_diagnosis(state: ReviewState):\n",
    "\n",
    "    prompt = f\"\"\"Diagnose this negative review:\\n\\n{state['review']}\\n\"\n",
    "    \"Return issue_type, tone, and urgency.\n",
    "\"\"\"\n",
    "    response = structured_model2.invoke(prompt)\n",
    "\n",
    "    return {'diagnosis': response.model_dump()}\n",
    "\n",
    "def negative_response(state: ReviewState):\n",
    "\n",
    "    diagnosis = state['diagnosis']\n",
    "\n",
    "    prompt = f\"\"\"You are a support assistant.\n",
    "The user had a '{diagnosis['issue_type']}' issue, sounded '{diagnosis['tone']}', and marked urgency as '{diagnosis['urgency']}'.\n",
    "Write an empathetic, helpful resolution message.\n",
    "\"\"\"\n",
    "    response = model.invoke(prompt).content\n",
    "\n",
    "    return {'response': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321df307",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ReviewState)\n",
    "\n",
    "graph.add_node('find_sentiment', find_sentiment)\n",
    "graph.add_node('positive_response', positive_response)\n",
    "graph.add_node('run_diagnosis', run_diagnosis)\n",
    "graph.add_node('negative_response', negative_response)\n",
    "\n",
    "graph.add_edge(START, 'find_sentiment')\n",
    "\n",
    "graph.add_conditional_edges('find_sentiment', check_sentiment)\n",
    "\n",
    "graph.add_edge('positive_response', END)\n",
    "\n",
    "graph.add_edge('run_diagnosis', 'negative_response')\n",
    "graph.add_edge('negative_response', END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ca529",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e681843",
   "metadata": {},
   "outputs": [],
   "source": [
    "intial_state={\n",
    "    'review': \"I’ve been trying to log in for over an hour now, and the app keeps freezing on the authentication screen. I even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.\"\n",
    "}\n",
    "workflow.invoke(intial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a94d30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87818040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca9cdd9e",
   "metadata": {},
   "source": [
    "### + Iterative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b973686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "evaluator_llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "optimizer_llm = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24849c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetEvaluation(BaseModel):\n",
    "    evaluation: Literal[\"approved\", \"needs_improvement\"] = Field(..., description=\"Final evaluation result.\")\n",
    "    feedback: str = Field(..., description=\"feedback for the tweet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_evaluator_llm = evaluator_llm.with_structured_output(TweetEvaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c14ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state\n",
    "class TweetState(TypedDict):\n",
    "\n",
    "    topic: str\n",
    "    tweet: str\n",
    "    evaluation: Literal[\"approved\", \"needs_improvement\"]\n",
    "    feedback: str\n",
    "    iteration: int\n",
    "    max_iteration: int\n",
    "\n",
    "    tweet_history: Annotated[list[str], operator.add]\n",
    "    feedback_history: Annotated[list[str], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a87f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tweet(state: TweetState):\n",
    "\n",
    "    # prompt\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a funny and clever Twitter/X influencer.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Write a short, original, and hilarious tweet on the topic: \"{state['topic']}\".\n",
    "\n",
    "Rules:\n",
    "- Do NOT use question-answer format.\n",
    "- Max 280 characters.\n",
    "- Use observational humor, irony, sarcasm, or cultural references.\n",
    "- Think in meme logic, punchlines, or relatable takes.\n",
    "- Use simple, day to day english\n",
    "\"\"\")\n",
    "    ]\n",
    "\n",
    "    # send generator_llm\n",
    "    response = generator_llm.invoke(messages).content\n",
    "\n",
    "    # return response\n",
    "    return {'tweet': response, 'tweet_history': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tweet(state: TweetState):\n",
    "\n",
    "    # prompt\n",
    "    messages = [\n",
    "    SystemMessage(content=\"You are a ruthless, no-laugh-given Twitter critic. You evaluate tweets based on humor, originality, virality, and tweet format.\"),\n",
    "    HumanMessage(content=f\"\"\"\n",
    "Evaluate the following tweet:\n",
    "\n",
    "Tweet: \"{state['tweet']}\"\n",
    "\n",
    "Use the criteria below to evaluate the tweet:\n",
    "\n",
    "1. Originality – Is this fresh, or have you seen it a hundred times before?  \n",
    "2. Humor – Did it genuinely make you smile, laugh, or chuckle?  \n",
    "3. Punchiness – Is it short, sharp, and scroll-stopping?  \n",
    "4. Virality Potential – Would people retweet or share it?  \n",
    "5. Format – Is it a well-formed tweet (not a setup-punchline joke, not a Q&A joke, and under 280 characters)?\n",
    "\n",
    "Auto-reject if:\n",
    "- It's written in question-answer format (e.g., \"Why did...\" or \"What happens when...\")\n",
    "- It exceeds 280 characters\n",
    "- It reads like a traditional setup-punchline joke\n",
    "- Dont end with generic, throwaway, or deflating lines that weaken the humor (e.g., “Masterpieces of the auntie-uncle universe” or vague summaries)\n",
    "\n",
    "### Respond ONLY in structured format:\n",
    "- evaluation: \"approved\" or \"needs_improvement\"  \n",
    "- feedback: One paragraph explaining the strengths and weaknesses \n",
    "\"\"\")\n",
    "]\n",
    "\n",
    "    response = structured_evaluator_llm.invoke(messages)\n",
    "\n",
    "    return {'evaluation':response.evaluation, 'feedback': response.feedback, 'feedback_history': [response.feedback]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_tweet(state: TweetState):\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You punch up tweets for virality and humor based on given feedback.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Improve the tweet based on this feedback:\n",
    "\"{state['feedback']}\"\n",
    "\n",
    "Topic: \"{state['topic']}\"\n",
    "Original Tweet:\n",
    "{state['tweet']}\n",
    "\n",
    "Re-write it as a short, viral-worthy tweet. Avoid Q&A style and stay under 280 characters.\n",
    "\"\"\")\n",
    "    ]\n",
    "\n",
    "    response = optimizer_llm.invoke(messages).content\n",
    "    iteration = state['iteration'] + 1\n",
    "\n",
    "    return {'tweet': response, 'iteration': iteration, 'tweet_history': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc328a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_evaluation(state: TweetState):\n",
    "\n",
    "    if state['evaluation'] == 'approved' or state['iteration'] >= state['max_iteration']:\n",
    "        return 'approved'\n",
    "    else:\n",
    "        return 'needs_improvement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(TweetState)\n",
    "\n",
    "graph.add_node('generate', generate_tweet)\n",
    "graph.add_node('evaluate', evaluate_tweet)\n",
    "graph.add_node('optimize', optimize_tweet)\n",
    "\n",
    "graph.add_edge(START, 'generate')\n",
    "graph.add_edge('generate', 'evaluate')\n",
    "\n",
    "graph.add_conditional_edges('evaluate', route_evaluation, {'approved': END, 'needs_improvement': 'optimize'})\n",
    "graph.add_edge('optimize', 'evaluate')\n",
    "\n",
    "workflow = graph.compile()\n",
    "\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a8ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"topic\": \"srhberhb\",\n",
    "    \"iteration\": 1,\n",
    "    \"max_iteration\": 5\n",
    "}\n",
    "result = workflow.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa87d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in result['tweet_history']:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b64c44",
   "metadata": {},
   "source": [
    "### Basic_Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "\n",
    "    messages: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e02400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: ChatState):\n",
    "\n",
    "    # take user query from state\n",
    "    messages = state['messages']\n",
    "\n",
    "    # send to llm\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # response store state\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e76272",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ChatState)\n",
    "\n",
    "# add nodes\n",
    "graph.add_node('chat_node', chat_node)\n",
    "\n",
    "graph.add_edge(START, 'chat_node')\n",
    "graph.add_edge('chat_node', END)\n",
    "\n",
    "chatbot = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffad0dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca158042",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    'messages': [HumanMessage(content='What is the capital of india')]\n",
    "}\n",
    "\n",
    "chatbot.invoke(initial_state)['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcde91e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95494a00",
   "metadata": {},
   "source": [
    "### Chatbot_Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9952ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokeState(TypedDict):\n",
    "\n",
    "    topic: str\n",
    "    joke: str\n",
    "    explanation: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9668efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_joke(state: JokeState):\n",
    "\n",
    "    prompt = f'generate a joke on the topic {state[\"topic\"]}'\n",
    "    response = llm.invoke(prompt).content\n",
    "\n",
    "    return {'joke': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ca032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explanation(state: JokeState):\n",
    "\n",
    "    prompt = f'write an explanation for the joke - {state[\"joke\"]}'\n",
    "    response = llm.invoke(prompt).content\n",
    "\n",
    "    return {'explanation': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6007b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(JokeState)\n",
    "\n",
    "graph.add_node('generate_joke', generate_joke)\n",
    "graph.add_node('generate_explanation', generate_explanation)\n",
    "\n",
    "graph.add_edge(START, 'generate_joke')\n",
    "graph.add_edge('generate_joke', 'generate_explanation')\n",
    "graph.add_edge('generate_explanation', END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "workflow = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99492992",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "workflow.invoke({'topic':'pizza'}, config=config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3672a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.get_state(config1)\n",
    "# list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e5f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "workflow.invoke({'topic':'pasta'}, config=config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time travel\n",
    "workflow.get_state({\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06cc6e-7232-6cb1-8000-f71609e6cec5\"}})\n",
    "workflow.invoke(None, {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06cc6e-7232-6cb1-8000-f71609e6cec5\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f38e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating state\n",
    "workflow.update_state({\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06cc6e-7232-6cb1-8000-f71609e6cec5\", \"checkpoint_ns\": \"\"}}, {'topic':'samosa'})\n",
    "workflow.invoke(None, {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06cc72-ca16-6359-8001-7eea05e07dd2\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a295af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fault tolerence\n",
    "# 1. Define the state\n",
    "class CrashState(TypedDict):\n",
    "    input: str\n",
    "    step1: str\n",
    "    step2: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20633a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_1(state: CrashState) -> CrashState:\n",
    "    print(\"✅ Step 1 executed\")\n",
    "    return {\"step1\": \"done\", \"input\": state[\"input\"]}\n",
    "\n",
    "def step_2(state: CrashState) -> CrashState:\n",
    "    print(\"⏳ Step 2 hanging... now manually interrupt from the notebook toolbar (STOP button)\")\n",
    "    time.sleep(1000)  # Simulate long-running hang\n",
    "    return {\"step2\": \"done\"}\n",
    "\n",
    "def step_3(state: CrashState) -> CrashState:\n",
    "    print(\"✅ Step 3 executed\")\n",
    "    return {\"done\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(CrashState)\n",
    "builder.add_node(\"step_1\", step_1)\n",
    "builder.add_node(\"step_2\", step_2)\n",
    "builder.add_node(\"step_3\", step_3)\n",
    "\n",
    "builder.set_entry_point(\"step_1\")\n",
    "builder.add_edge(\"step_1\", \"step_2\")\n",
    "builder.add_edge(\"step_2\", \"step_3\")\n",
    "builder.add_edge(\"step_3\", END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d930e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"▶️ Running graph: Please manually interrupt during Step 2...\")\n",
    "    graph.invoke({\"input\": \"start\"}, config={\"configurable\": {\"thread_id\": 'thread-1'}})\n",
    "except KeyboardInterrupt:\n",
    "    print(\"❌ Kernel manually interrupted (crash simulated).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69465c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🔁 Re-running the graph to demonstrate fault tolerance...\")\n",
    "final_state = graph.invoke(None, config={\"configurable\": {\"thread_id\": 'thread-1'}})\n",
    "print(\"\\n✅ Final State:\", final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa74f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(graph.get_state_history({\"configurable\": {\"thread_id\": 'thread-1'}}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
