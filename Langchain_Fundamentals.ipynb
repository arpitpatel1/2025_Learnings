{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0566104e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard library\n",
    "import os\n",
    "from typing import Type, TypedDict, Annotated, Optional, Literal\n",
    "\n",
    "# Third-party libraries\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api._errors import TranscriptsDisabled, NoTranscriptFound\n",
    "\n",
    "# LangChain OpenAI & HuggingFace\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_huggingface import (\n",
    "    ChatHuggingFace,\n",
    "    HuggingFaceEndpoint,\n",
    "    HuggingFacePipeline,\n",
    ")\n",
    "\n",
    "# LangChain core modules\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import (\n",
    "    StrOutputParser,\n",
    "    JsonOutputParser,\n",
    "    PydanticOutputParser,\n",
    ")\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.tools import tool, InjectedToolArg\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# LangChain prompts & parsing\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "# LangChain community modules\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# LangChain text processing\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# LangChain tools & agents\n",
    "from langchain.tools import BaseTool, StructuredTool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "# openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2b963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aa4d88",
   "metadata": {},
   "source": [
    "### Simple QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e437765b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beneath the sun, the players stand tall,  \n",
      "With bat and ball, they heed the call.  \n",
      "A crack of wood, the crowd's wild cheer,  \n",
      "In every match, the thrill draws near.  \n",
      "In cricket's dance, we find our grace, a timeless game, a cherished space.  \n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"Write a 5 line poem on cricket\")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c06d12c",
   "metadata": {},
   "source": [
    "### + Local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca2551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HF API endpoint\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.2-1B\",\n",
    "    task=\"text-generation\",\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "result = model.invoke(\"What is the capital of India\")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ecf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local\n",
    "os.environ['HF_HOME'] = 'D:/huggingface_cache'\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id='meta-llama/Llama-3.2-1B',\n",
    "    task='text-generation',\n",
    "    pipeline_kwargs=dict(\n",
    "        temperature=0.5,\n",
    "        max_new_tokens=100\n",
    "    )\n",
    ")\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "result = model.invoke(\"What is the capital of India\")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb7b84",
   "metadata": {},
   "source": [
    "### + Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a helpful assistant. Answer the question clearly and concisely.\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "\n",
    "formatted_prompt = prompt.invoke({'question':\"Why is the sky blue?\"})\n",
    "result = llm.invoke(formatted_prompt)\n",
    "\n",
    "chain = prompt | llm \n",
    "result2 = chain.invoke({'question':\"Why is the sky blue?\"})\n",
    "\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa09b5",
   "metadata": {},
   "source": [
    "### + Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a55e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Your source documents\n",
    "documents = [\n",
    "    Document(page_content=\"LangChain helps developers build LLM applications easily.\"),\n",
    "    Document(page_content=\"Chroma is a vector database optimized for LLM-based search.\"),\n",
    "    Document(page_content=\"Embeddings convert text into high-dimensional vectors.\"),\n",
    "    Document(page_content=\"OpenAI provides powerful embedding models.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8531632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize embedding model\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Step 3: Create Chroma vector store in memory\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"my_collection\"\n",
    ")\n",
    "# Step 4: Convert vectorstore into a retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c87460",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Chroma used for?\"\n",
    "results = retriever.invoke(query)\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1eaee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a17fd09",
   "metadata": {},
   "source": [
    "### + RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e4f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api._errors import TranscriptsDisabled, NoTranscriptFound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f88f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = \"Gfr50f6ZBvo\"  # only the ID, not full URL\n",
    "\n",
    "try:\n",
    "    # Fetch transcript in English\n",
    "    ytt_api = YouTubeTranscriptApi()\n",
    "    transcript_list = ytt_api.fetch(video_id= \"Gfr50f6ZBvo\", languages=[\"en\"])\n",
    "\n",
    "    # Flatten it to plain text\n",
    "    transcript = \" \".join([chunk.text for chunk in transcript_list])\n",
    "    print(transcript)\n",
    "\n",
    "except TranscriptsDisabled:\n",
    "    print(\"No captions available for this video.\")\n",
    "\n",
    "except NoTranscriptFound:\n",
    "    print(\"No transcript found in the requested language(s).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.create_documents([transcript])\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a426a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "vector_store.index_to_docstore_id\n",
    "# vector_store.get_by_ids(['2436bdb8-3f5f-49c6-8915-0c654c888700'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c6970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "retriever.invoke('What is deepmind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201be6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "      You are a helpful assistant.\n",
    "      Answer ONLY from the provided transcript context.\n",
    "      If the context is insufficient, just say you don't know.\n",
    "\n",
    "      {context}\n",
    "      Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables = ['context', 'question']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc484fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "question          = \"is the topic of nuclear fusion discussed in this video? if yes then what was discussed\"\n",
    "retrieved_docs    = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238dea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})\n",
    "answer = llm.invoke(final_prompt)\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac0b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain \n",
    "\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_docs(retrieved_docs):\n",
    "  context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "  return context_text\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    'context': retriever | RunnableLambda(format_docs),\n",
    "    'question': RunnablePassthrough()\n",
    "})\n",
    "parallel_chain.invoke('who is Demis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0a03ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()\n",
    "main_chain = parallel_chain | prompt | llm | parser\n",
    "main_chain.invoke('Can you summarize the video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e83c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78a83339",
   "metadata": {},
   "source": [
    "### + Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e411f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2acd09f",
   "metadata": {},
   "source": [
    "### + Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1e9f43",
   "metadata": {},
   "source": [
    "#### with_structured_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a117a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - typeddict (define, no validation, kind of hint, annotated to give description)\n",
    "class Review(TypedDict):\n",
    "\n",
    "    key_themes: Annotated[list[str], \"Write down all the key themes discussed in the review in a list\"]\n",
    "    summary: Annotated[str, \"A brief summary of the review\"]\n",
    "    sentiment: Annotated[Literal[\"pos\", \"neg\"], \"Return sentiment of the review either negative, positive or neutral\"]\n",
    "    pros: Annotated[Optional[list[str]], \"Write down all the pros inside a list\"]\n",
    "    cons: Annotated[Optional[list[str]], \"Write down all the cons inside a list\"]\n",
    "    name: Annotated[Optional[str], \"Write the name of the reviewer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - pydantic (basemodel, validation , field for description and other control)\n",
    "class Review(BaseModel):\n",
    "\n",
    "    key_themes: list[str] = Field(description=\"Write down all the key themes discussed in the review in a list\")\n",
    "    summary: str = Field(description=\"A brief summary of the review\")\n",
    "    sentiment: Literal[\"pos\", \"neg\"] = Field(description=\"Return sentiment of the review either negative, positive or neutral\")\n",
    "    pros: Optional[list[str]] = Field(default=None, description=\"Write down all the pros inside a list\")\n",
    "    cons: Optional[list[str]] = Field(default=None, description=\"Write down all the cons inside a list\")\n",
    "    name: Optional[str] = Field(default=None, description=\"Write the name of the reviewer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1063bc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - json_schema (across language, data validation and structure schema)\n",
    "json_schema = {\n",
    "  \"title\": \"Review\",\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"key_themes\": {\n",
    "      \"type\": \"array\",\n",
    "      \"items\": {\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      \"description\": \"Write down all the key themes discussed in the review in a list\"\n",
    "    },\n",
    "    \"summary\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"A brief summary of the review\"\n",
    "    },\n",
    "    \"sentiment\": {\n",
    "      \"type\": \"string\",\n",
    "      \"enum\": [\"pos\", \"neg\"],\n",
    "      \"description\": \"Return sentiment of the review either negative, positive or neutral\"\n",
    "    },\n",
    "    \"pros\": {\n",
    "      \"type\": [\"array\", \"null\"],\n",
    "      \"items\": {\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      \"description\": \"Write down all the pros inside a list\"\n",
    "    },\n",
    "    \"cons\": {\n",
    "      \"type\": [\"array\", \"null\"],\n",
    "      \"items\": {\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      \"description\": \"Write down all the cons inside a list\"\n",
    "    },\n",
    "    \"name\": {\n",
    "      \"type\": [\"string\", \"null\"],\n",
    "      \"description\": \"Write the name of the reviewer\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"key_themes\", \"summary\", \"sentiment\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e08cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model = llm.with_structured_output(json_schema)\n",
    "# structured_model = model.with_structured_output(Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = structured_model.invoke(\"\"\"I recently upgraded to the Samsung Galaxy S24 Ultra, and I must say, it’s an absolute powerhouse! The Snapdragon 8 Gen 3 processor makes everything lightning fast—whether I’m gaming, multitasking, or editing photos. The 5000mAh battery easily lasts a full day even with heavy use, and the 45W fast charging is a lifesaver.\n",
    "\n",
    "The S-Pen integration is a great touch for note-taking and quick sketches, though I don't use it often. What really blew me away is the 200MP camera—the night mode is stunning, capturing crisp, vibrant images even in low light. Zooming up to 100x actually works well for distant objects, but anything beyond 30x loses quality.\n",
    "\n",
    "However, the weight and size make it a bit uncomfortable for one-handed use. Also, Samsung’s One UI still comes with bloatware—why do I need five different Samsung apps for things Google already provides? The $1,300 price tag is also a hard pill to swallow.\n",
    "\n",
    "Pros:\n",
    "Insanely powerful processor (great for gaming and productivity)\n",
    "Stunning 200MP camera with incredible zoom capabilities\n",
    "Long battery life with fast charging\n",
    "S-Pen support is unique and useful\n",
    "                                 \n",
    "Review by Nitish Singh\n",
    "\"\"\")\n",
    "\n",
    "print(result['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6847717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3f8edda",
   "metadata": {},
   "source": [
    "#### OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaede16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StrOutputParser\n",
    "\n",
    "template1 = PromptTemplate(\n",
    "    template='Write a detailed report on {topic}',\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "# 2nd prompt -> summary\n",
    "template2 = PromptTemplate(\n",
    "    template='Write a 5 line summary on the following text. /n {text}',\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = template1 | model | parser | template2 | model | parser\n",
    "\n",
    "result = chain.invoke({'topic':'black hole'})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8784b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JsonOutputParser\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template='Give me 5 facts about {topic} \\n {format_instruction}',\n",
    "    input_variables=['topic'],\n",
    "    partial_variables={'format_instruction': parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = template | model | parser\n",
    "\n",
    "result = chain.invoke({'topic':'black hole'})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5c5b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StructuredOutputParser\n",
    "\n",
    "schema = [\n",
    "    ResponseSchema(name='fact_1', description='Fact 1 about the topic'),\n",
    "    ResponseSchema(name='fact_2', description='Fact 2 about the topic'),\n",
    "    ResponseSchema(name='fact_3', description='Fact 3 about the topic'),\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(schema)\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template='Give 3 fact about {topic} \\n {format_instruction}',\n",
    "    input_variables=['topic'],\n",
    "    partial_variables={'format_instruction':parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = template | model | parser\n",
    "\n",
    "result = chain.invoke({'topic':'black hole'})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12508f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PydanticOutputParser\n",
    "\n",
    "class Person(BaseModel):\n",
    "\n",
    "    name: str = Field(description='Name of the person')\n",
    "    age: int = Field(gt=18, description='Age of the person')\n",
    "    city: str = Field(description='Name of the city the person belongs to')\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Person)\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template='Generate the name, age and city of a fictional {place} person \\n {format_instruction}',\n",
    "    input_variables=['place'],\n",
    "    partial_variables={'format_instruction':parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = template | model | parser\n",
    "\n",
    "final_result = chain.invoke({'place':'sri lankan'})\n",
    "\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991eea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f96e65d4",
   "metadata": {},
   "source": [
    "### + Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fb6d9c",
   "metadata": {},
   "source": [
    "Tool Creation,\n",
    "Tool Binding,\n",
    "Tool Calling,\n",
    "Tool Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "results = search_tool.invoke('top news in india today')\n",
    "\n",
    "print(results)\n",
    "print(search_tool.name)\n",
    "print(search_tool.description)\n",
    "print(search_tool.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39380ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b436a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b:int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a*b\n",
    "\n",
    "result = multiply.invoke({\"a\":3, \"b\":5})\n",
    "print(result)\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)\n",
    "print(multiply.args_schema.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b34e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2\n",
    "from langchain.tools import StructuredTool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class MultiplyInput(BaseModel):\n",
    "    a: int = Field(required=True, description=\"The first number to add\")\n",
    "    b: int = Field(required=True, description=\"The second number to add\")\n",
    "\n",
    "def multiply_func(a: int, b: int) -> int:\n",
    "    return a * b\n",
    "\n",
    "multiply_tool = StructuredTool.from_function(\n",
    "    func=multiply_func,\n",
    "    name=\"multiply\",\n",
    "    description=\"Multiply two numbers\",\n",
    "    args_schema=MultiplyInput\n",
    ")\n",
    "\n",
    "result = multiply_tool.invoke({'a':3, 'b':3})\n",
    "\n",
    "print(result)\n",
    "print(multiply_tool.name)\n",
    "\n",
    "print(multiply_tool.description)\n",
    "print(multiply_tool.args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a6b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3\n",
    "from langchain.tools import BaseTool\n",
    "from typing import Type\n",
    "\n",
    "# arg schema using pydantic\n",
    "\n",
    "class MultiplyInput(BaseModel):\n",
    "    a: int = Field(required=True, description=\"The first number to add\")\n",
    "    b: int = Field(required=True, description=\"The second number to add\")\n",
    "\n",
    "class MultiplyTool(BaseTool):\n",
    "    name: str = \"multiply\"\n",
    "    description: str = \"Multiply two numbers\"\n",
    "\n",
    "    args_schema: Type[BaseModel] = MultiplyInput\n",
    "\n",
    "    def _run(self, a: int, b: int) -> int:\n",
    "        return a * b\n",
    "\n",
    "multiply_tool = MultiplyTool()\n",
    "\n",
    "result = multiply_tool.invoke({'a':3, 'b':3})\n",
    "\n",
    "print(result)\n",
    "print(multiply_tool.name)\n",
    "print(multiply_tool.description)\n",
    "\n",
    "print(multiply_tool.args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f42278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toolkit\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Custom tools\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b\n",
    "\n",
    "class MathToolkit:\n",
    "    def get_tools(self):\n",
    "        return [add, multiply]\n",
    "\n",
    "toolkit = MathToolkit()\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "for tool in tools:\n",
    "    print(tool.name, \"=>\", tool.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617c05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool binding\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f4df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "  \"\"\"Given 2 numbers a and b this tool returns their product\"\"\"\n",
    "  return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "llm_with_tools.invoke('Hi how are you')\n",
    "\n",
    "query = HumanMessage('can you multiply 3 with 1000')\n",
    "messages = [query]\n",
    "result = llm_with_tools.invoke(messages)\n",
    "messages.append(result)\n",
    "\n",
    "tool_result = multiply.invoke(result.tool_calls[0])\n",
    "messages.append(tool_result)\n",
    "\n",
    "llm_with_tools.invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26368674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example \n",
    "from langchain_core.tools import InjectedToolArg\n",
    "from typing import Annotated\n",
    "\n",
    "@tool\n",
    "def get_conversion_factor(base_currency: str, target_currency: str) -> float:\n",
    "  \"\"\"\n",
    "  This function fetches the currency conversion factor between a given base currency and a target currency\n",
    "  \"\"\"\n",
    "  url = f'https://v6.exchangerate-api.com/v6/c754eab14ffab33112e380ca/pair/{base_currency}/{target_currency}'\n",
    "\n",
    "  response = requests.get(url)\n",
    "\n",
    "  return response.json()\n",
    "\n",
    "@tool\n",
    "def convert(base_currency_value: int, conversion_rate: Annotated[float, InjectedToolArg]) -> float:\n",
    "  \"\"\"\n",
    "  given a currency conversion rate this function calculates the target currency value from a given base currency value\n",
    "  \"\"\"\n",
    "\n",
    "  return base_currency_value * conversion_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf97913",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_conversion_factor.invoke({'base_currency':'USD','target_currency':'INR'})\n",
    "convert.invoke({'base_currency_value':10, 'conversion_rate':85.16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f199593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool binding\n",
    "llm = ChatOpenAI()\n",
    "llm_with_tools = llm.bind_tools([get_conversion_factor, convert])\n",
    "messages = [HumanMessage('What is the conversion factor between INR and USD, and based on that can you convert 10 inr to usd')]\n",
    "ai_message = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_message)\n",
    "\n",
    "import json\n",
    "\n",
    "for tool_call in ai_message.tool_calls:\n",
    "  # execute the 1st tool and get the value of conversion rate\n",
    "  if tool_call['name'] == 'get_conversion_factor':\n",
    "    tool_message1 = get_conversion_factor.invoke(tool_call)\n",
    "    # fetch this conversion rate\n",
    "    conversion_rate = json.loads(tool_message1.content)['conversion_rate']\n",
    "    # append this tool message to messages list\n",
    "    messages.append(tool_message1)\n",
    "  # execute the 2nd tool using the conversion rate from tool 1\n",
    "  if tool_call['name'] == 'convert':\n",
    "    # fetch the current arg\n",
    "    tool_call['args']['conversion_rate'] = conversion_rate\n",
    "    tool_message2 = convert.invoke(tool_call)\n",
    "    messages.append(tool_message2)\n",
    "\n",
    "llm_with_tools.invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d25408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e807c52c",
   "metadata": {},
   "source": [
    "### + Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e900836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# Step 5: Initialize the Agent ---\n",
    "agent_executor = initialize_agent(\n",
    "    tools=[get_conversion_factor, convert],\n",
    "    llm=llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,  # using ReAct pattern\n",
    "    verbose=True  # shows internal thinking\n",
    ")\n",
    "\n",
    "# --- Step 6: Run the Agent ---\n",
    "user_query = \"Hi how are you?\"\n",
    "\n",
    "response = agent_executor.invoke({\"input\": user_query})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf29d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
